{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YButf8PRhRuF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "be60b9d4-53b9-468c-b7f1-3b82b1d6fedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Please upload your kaggle.json file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed7d63ab-7f01-44bc-9549-fbd2732645e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed7d63ab-7f01-44bc-9549-fbd2732645e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/landlord/handwriting-recognition\n",
            "License(s): CC0-1.0\n",
            "Downloading handwriting-recognition.zip to /content\n",
            " 99% 1.25G/1.26G [00:08<00:00, 235MB/s]\n",
            "100% 1.26G/1.26G [00:08<00:00, 163MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Google Colab and Kaggle Setup\n",
        "# -----------------------------------------\n",
        "# 1. Mount Google Drive: UNCOMMENT the two lines below to save your model to Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Install Kaggle API\n",
        "!pip install -q kaggle\n",
        "\n",
        "# 3. Upload your kaggle.json file\n",
        "# How to Get Your kaggle.json File\n",
        "# -Log in to your Kaggle account.\n",
        "# -Navigate to your Account settings by clicking on your profile picture in the top-right corner and selecting \"Settings.\"\n",
        "# -Scroll down to the API section.\n",
        "# -Click on the \"Create New API Token\" button. This will immediately trigger the download of the kaggle.json file to your computer.\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Please upload your kaggle.json file\")\n",
        "files.upload()\n",
        "\n",
        "# 4. Configure Kaggle and Download Dataset\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d landlord/handwriting-recognition\n",
        "!unzip -q handwriting-recognition.zip -d handwriting_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "# -----------------------------------------\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "rXSOojdPnJWx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration and Hyperparameters\n",
        "# -----------------------------------------\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class Config:\n",
        "\n",
        "    DATA_DIR = './handwriting_data/'\n",
        "    TRAIN_CSV_PATH = os.path.join(DATA_DIR, 'written_name_train_v2.csv')\n",
        "    VALIDATION_CSV_PATH = os.path.join(DATA_DIR, 'written_name_validation_v2.csv')\n",
        "    TEST_CSV_PATH = os.path.join(DATA_DIR, 'written_name_test_v2.csv')\n",
        "\n",
        "    # After mounting your drive, this path will point to a folder where the model is saved.\n",
        "    # For example: '/content/drive/MyDrive/MyModels/handwriting_model.pth'\n",
        "    # If you don't mount Google Drive, it will save to the Colab environment.\n",
        "    MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab/Models/handwriting_crnn_model.pth'\n",
        "\n",
        "    # Image parameters\n",
        "    IMG_HEIGHT = 64\n",
        "    IMG_WIDTH = 256\n",
        "\n",
        "    # Model parameters\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 20\n",
        "    LEARNING_RATE = 0.0005\n",
        "\n",
        "    # Character set\n",
        "    # Dynamically build the character set from the dataset labels\n",
        "    def build_char_set(self):\n",
        "        all_chars = set()\n",
        "        try:\n",
        "            train_df = pd.read_csv(self.TRAIN_CSV_PATH).dropna()\n",
        "            val_df = pd.read_csv(self.VALIDATION_CSV_PATH).dropna()\n",
        "            test_df = pd.read_csv(self.TEST_CSV_PATH).dropna()\n",
        "\n",
        "            for label in train_df['IDENTITY']:\n",
        "                all_chars.update(str(label))\n",
        "            for label in val_df['IDENTITY']:\n",
        "                 all_chars.update(str(label))\n",
        "            for label in test_df['IDENTITY']:\n",
        "                 all_chars.update(str(label))\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: Dataset CSV files not found. Using a default character set.\")\n",
        "            all_chars = set(\" !\\\"#&'()*+,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "\n",
        "        # Sort characters to ensure consistent mapping\n",
        "        sorted_chars = sorted(list(all_chars))\n",
        "        # The character set should include all possible characters in the labels\n",
        "        # plus a blank character for CTC loss, which is usually at index 0\n",
        "        self.CHAR_SET = \"\".join(sorted_chars)\n",
        "        self.CHAR_TO_INT = {char: i + 1 for i, char in enumerate(self.CHAR_SET)}\n",
        "        self.INT_TO_CHAR = {i + 1: char for i, char in enumerate(self.CHAR_SET)}\n",
        "        self.VOCAB_SIZE = len(self.CHAR_SET) + 1 # +1 for the blank token\n",
        "\n",
        "# Instantiate the config and build the character set\n",
        "config = Config()\n",
        "config.build_char_set()\n",
        "\n",
        "print(f\"Character set size: {config.VOCAB_SIZE}\")\n",
        "# print(f\"Character set: {config.CHAR_SET}\") # Uncomment to see the full character set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMnN4lNAnmC7",
        "outputId": "5ae06769-f9f9-4988-97dd-c8e18784fd0a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character set size: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading and Preprocessing\n",
        "# --------------------------------------\n",
        "\n",
        "class HandwritingDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for the handwriting recognition data.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, data_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (pandas.DataFrame): DataFrame with image names and labels.\n",
        "            data_dir (str): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Get image path and label\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        label = self.df.iloc[idx, 1]\n",
        "\n",
        "        # Construct full image path\n",
        "        # The CSV contains paths like 'TRAIN_00001.jpg', so we need to find the correct subfolder\n",
        "        # The data is structured in folders like 'train_v2/train/'\n",
        "        # Let's find the correct path\n",
        "\n",
        "        folder_prefix = img_name.split('_')[0].lower() # e.g., 'TRAIN' -> 'train'\n",
        "        sub_folder = f\"{folder_prefix}_v2/{folder_prefix}\"\n",
        "        img_path = os.path.join(self.data_dir, sub_folder, img_name)\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('L') # Convert to grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Encode the label\n",
        "        encoded_label = [config.CHAR_TO_INT[char] for char in str(label)]\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'label': torch.tensor(encoded_label, dtype=torch.long),\n",
        "            'label_length': torch.tensor([len(encoded_label)], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Define transformations\n",
        "# We resize, pad if necessary, and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads and prepares the datasets and dataloaders.\"\"\"\n",
        "    # Read CSVs and drop rows with missing labels\n",
        "    train_df = pd.read_csv(config.TRAIN_CSV_PATH).dropna().reset_index(drop=True)\n",
        "    validation_df = pd.read_csv(config.VALIDATION_CSV_PATH).dropna().reset_index(drop=True)\n",
        "    test_df = pd.read_csv(config.TEST_CSV_PATH).dropna().reset_index(drop=True)\n",
        "\n",
        "    # For demonstration, let's use a smaller subset of the data to speed up training\n",
        "    # You can comment this out to use the full dataset\n",
        "    train_df = train_df.sample(n=20000, random_state=42)\n",
        "    validation_df = validation_df.sample(n=4000, random_state=42)\n",
        "\n",
        "    train_dataset = HandwritingDataset(train_df, config.DATA_DIR, transform=transform)\n",
        "    validation_dataset = HandwritingDataset(validation_df, config.DATA_DIR, transform=transform)\n",
        "    test_dataset = HandwritingDataset(test_df, config.DATA_DIR, transform=transform)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"Custom collate function to handle variable length labels.\"\"\"\n",
        "        images = torch.stack([item['image'] for item in batch])\n",
        "        labels = [item['label'] for item in batch]\n",
        "        label_lengths = torch.stack([item['label_length'] for item in batch]).squeeze()\n",
        "\n",
        "        # Pad labels to the max length in the batch\n",
        "        labels_padded = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
        "\n",
        "        return images, labels_padded, label_lengths\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader"
      ],
      "metadata": {
        "id": "H1sYH8K1oRDk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CRNN Model Architecture\n",
        "# -------------------------------\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Recurrent Neural Network (CRNN)\n",
        "    \"\"\"\n",
        "    def __init__(self, img_channels, vocab_size, rnn_hidden_size=256, rnn_layers=2):\n",
        "        super(CRNN, self).__init__()\n",
        "\n",
        "        # --- CNN Feature Extractor ---\n",
        "        # This architecture is designed to take an image of size (C, 64, 256)\n",
        "        # and output a feature map of size (512, 1, 64)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 64 x 32 x 128\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 128 x 16 x 64\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)),  # Output: 256 x 8 x 64\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)),  # Output: 512 x 4 x 64\n",
        "\n",
        "            # This final convolution reduces the height to 1\n",
        "            # H_out = floor((4 + 2*0 - 4)/1 + 1) = 1\n",
        "            nn.Conv2d(512, 512, kernel_size=(4, 1), stride=(1, 1), padding=(0, 0)), # Output: 512 x 1 x 64\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # --- Map-to-Sequence ---\n",
        "        self.map_to_seq = nn.Linear(512, rnn_hidden_size)\n",
        "\n",
        "        # --- RNN Sequence Processor ---\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=rnn_hidden_size,\n",
        "            hidden_size=rnn_hidden_size,\n",
        "            num_layers=rnn_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # --- Fully Connected Layer for Transcription ---\n",
        "        self.fc = nn.Linear(rnn_hidden_size * 2, vocab_size) # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN forward pass\n",
        "        conv_features = self.cnn(x) # (B, C, H, W) -> (B, 512, 1, 64)\n",
        "\n",
        "        # Permute and reshape for RNN\n",
        "        conv_features = conv_features.squeeze(2) # (B, 512, 64)\n",
        "        conv_features = conv_features.permute(0, 2, 1) # (B, 64, 512) -> (Batch, SeqLen, Features)\n",
        "\n",
        "        # Map to sequence\n",
        "        seq_features = self.map_to_seq(conv_features)\n",
        "\n",
        "        # RNN forward pass\n",
        "        rnn_output, _ = self.rnn(seq_features) # (B, SeqLen, HiddenSize*2)\n",
        "\n",
        "        # Transcription layer\n",
        "        output = self.fc(rnn_output) # (B, SeqLen, VocabSize)\n",
        "\n",
        "        # For CTC Loss, the output needs to be (SeqLen, Batch, VocabSize)\n",
        "        output = output.permute(1, 0, 2)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "o5N_J6Er0I_H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation\n",
        "# -------------------------------\n",
        "\n",
        "def ctc_decode(preds, int_to_char_map):\n",
        "    \"\"\"\n",
        "    Decodes the output of the network using a greedy approach (best path).\n",
        "    \"\"\"\n",
        "    preds_idx = torch.argmax(preds, dim=2)\n",
        "    preds_idx = preds_idx.transpose(1, 0) # (Batch, SeqLen)\n",
        "\n",
        "    decoded_texts = []\n",
        "    for i in range(preds_idx.shape[0]):\n",
        "        t = preds_idx[i]\n",
        "        # Remove consecutive duplicates and blank tokens (index 0)\n",
        "        deblanked_t = [p for p in t if p != 0]\n",
        "        unique_t = [deblanked_t[j] for j in range(len(deblanked_t)) if j == 0 or deblanked_t[j] != deblanked_t[j-1]]\n",
        "\n",
        "        text = ''.join([int_to_char_map.get(c.item(), '') for c in unique_t])\n",
        "        decoded_texts.append(text)\n",
        "\n",
        "    return decoded_texts\n",
        "\n",
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    \"\"\"Trains the model for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "        images, labels, label_lengths = batch\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        label_lengths = label_lengths.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        preds = model(images)\n",
        "        log_probs = F.log_softmax(preds, dim=2)\n",
        "\n",
        "        # Calculate input lengths for CTC loss\n",
        "        # The sequence length from the model is preds.size(0)\n",
        "        input_lengths = torch.full(size=(images.size(0),), fill_value=preds.size(0), dtype=torch.long)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(log_probs, labels, input_lengths, label_lengths)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # Clip gradients to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate(model, criterion, val_loader, device):\n",
        "    \"\"\"Validates the model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            images, labels, label_lengths = batch\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            label_lengths = label_lengths.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            preds = model(images)\n",
        "            log_probs = F.log_softmax(preds, dim=2)\n",
        "            input_lengths = torch.full(size=(images.size(0),), fill_value=preds.size(0), dtype=torch.long)\n",
        "\n",
        "            # Loss\n",
        "            loss = criterion(log_probs, labels, input_lengths, label_lengths)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Decode predictions for evaluation\n",
        "            decoded_preds = ctc_decode(preds.cpu(), config.INT_TO_CHAR)\n",
        "            all_preds.extend(decoded_preds)\n",
        "\n",
        "            # Decode ground truth labels\n",
        "            for l in labels:\n",
        "                text = ''.join([config.INT_TO_CHAR.get(c.item(), '') for c in l if c != 0])\n",
        "                all_labels.append(text)\n",
        "\n",
        "    # Calculate Character Error Rate (CER) and Word Error Rate (WER) - simplified\n",
        "    # Note: A proper CER/WER calculation uses edit distance. This is a simple accuracy check.\n",
        "    correct_predictions = sum(1 for p, l in zip(all_preds, all_labels) if p == l)\n",
        "    accuracy = correct_predictions / len(all_labels)\n",
        "\n",
        "    return total_loss / len(val_loader), accuracy\n"
      ],
      "metadata": {
        "id": "OjRXby9K2Dgd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the training and validation process.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_loader, val_loader, _ = load_data()\n",
        "\n",
        "    model = CRNN(img_channels=1, vocab_size=config.VOCAB_SIZE).to(device)\n",
        "    criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{config.EPOCHS} ---\")\n",
        "        train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "        val_loss, val_accuracy = validate(model, criterion, val_loader, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\")\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            # Use the path from the config\n",
        "            torch.save(model.state_dict(), config.MODEL_SAVE_PATH)\n",
        "            print(f\"Model saved as {config.MODEL_SAVE_PATH}\")\n",
        "\n",
        "    print(\"\\nTraining finished!\")\n",
        "\n",
        "    model.load_state_dict(torch.load(config.MODEL_SAVE_PATH))\n",
        "    print(\"Best model loaded for prediction.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "PYT3-ojTMjsN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on a Single Image\n",
        "# ------------------------------------\n",
        "def predict_word(model, image_path, device):\n",
        "    \"\"\"\n",
        "    Takes an image path and predicts the handwritten word.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess the image\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image = transform(image).unsqueeze(0) # Add batch dimension\n",
        "    image = image.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(image)\n",
        "\n",
        "    # Decode the prediction\n",
        "    decoded_text = ctc_decode(preds.cpu(), config.INT_TO_CHAR)\n",
        "\n",
        "    # Display the image and prediction\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    plt.imshow(Image.open(image_path), cmap='gray')\n",
        "    plt.title(f\"Predicted Word: {decoded_text[0]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return decoded_text[0]"
      ],
      "metadata": {
        "id": "LDM5uQkA2TXB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution ---\n",
        "if __name__ == '__main__':\n",
        "    # This check prevents running the training automatically when the script is imported.\n",
        "    # To train the model, uncomment the following line in your Colab notebook.\n",
        "\n",
        "    #trained_model = main()\n",
        "\n",
        "    # --- Example of how to use the prediction function ---\n",
        "    # You would need a trained model file ('best_crnn_model.pth') and an image.\n",
        "\n",
        "    print(\"\\nTo run prediction, you need a trained model.\")\n",
        "    print(\"First, run the main() function to train and save a model.\")\n",
        "    print(\"Then, you can use the predict_word() function like this:\")\n",
        "    print(\"`predict_word(trained_model, 'path/to/your/image.png', device)`\")\n",
        "\n",
        "    # Example usage with a sample image from the validation set\n",
        "    # Let's find a sample image to test with\n",
        "    try:\n",
        "        validation_df_for_pred = pd.read_csv(config.VALIDATION_CSV_PATH).dropna().reset_index(drop=True)\n",
        "        sample_row = validation_df_for_pred.sample(1).iloc[0]\n",
        "        sample_img_name = sample_row['FILENAME']\n",
        "        sample_label = sample_row['IDENTITY']\n",
        "\n",
        "        sample_img_path = os.path.join(config.DATA_DIR, 'validation_v2/validation', sample_img_name)\n",
        "\n",
        "        if os.path.exists(sample_img_path):\n",
        "            print(f\"\\n--- Running Prediction on a Sample Image ---\")\n",
        "            print(f\"Image: {sample_img_name}, True Label: {sample_label}\")\n",
        "\n",
        "            # Load a pre-trained model if it exists, otherwise you need to train first\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            prediction_model = CRNN(img_channels=1, vocab_size=config.VOCAB_SIZE).to(device)\n",
        "\n",
        "            if os.path.exists(config.MODEL_SAVE_PATH):\n",
        "                prediction_model.load_state_dict(torch.load(config.MODEL_SAVE_PATH, map_location=device))\n",
        "                predict_word(prediction_model, sample_img_path, device)\n",
        "            else:\n",
        "                print(f\"\\nCould not find {config.MODEL_SAVE_PATH}.\")\n",
        "                print(\"Please train the model first by uncommenting and running `trained_model = main()`\")\n",
        "        else:\n",
        "            print(f\"Could not find sample image at: {sample_img_path}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nCould not find validation CSV. Please ensure the dataset is downloaded and extracted correctly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "HDgHXE6ZUcWy",
        "outputId": "a54d3656-e887-47ef-bcaa-490c42692cfa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "To run prediction, you need a trained model.\n",
            "First, run the main() function to train and save a model.\n",
            "Then, you can use the predict_word() function like this:\n",
            "`predict_word(trained_model, 'path/to/your/image.png', device)`\n",
            "\n",
            "--- Running Prediction on a Sample Image ---\n",
            "Image: VALIDATION_15494.jpg, True Label: BEAULIEN-CAMUS\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}