{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f128981227384236b16635267255335b": {
          "model_module": "ipycanvas",
          "model_name": "CanvasModel",
          "model_module_version": "^0.13",
          "state": {
            "_canvas_manager": "IPY_MODEL_1bec5f64caf34a93bebdbf9c5f4f341c",
            "_dom_classes": [],
            "_model_module": "ipycanvas",
            "_model_module_version": "^0.13",
            "_model_name": "CanvasModel",
            "_send_client_ready_event": true,
            "_view_count": null,
            "_view_module": "ipycanvas",
            "_view_module_version": "^0.13",
            "_view_name": "CanvasView",
            "height": 64,
            "image_data": null,
            "layout": "IPY_MODEL_54e6b1f25ce845b3ae2ef1fb4437effd",
            "sync_image_data": true,
            "width": 256
          }
        },
        "1bec5f64caf34a93bebdbf9c5f4f341c": {
          "model_module": "ipycanvas",
          "model_name": "CanvasManagerModel",
          "model_module_version": "^0.13",
          "state": {
            "_model_module": "ipycanvas",
            "_model_module_version": "^0.13",
            "_model_name": "CanvasManagerModel",
            "_view_count": null,
            "_view_module": null,
            "_view_module_version": "",
            "_view_name": null
          }
        },
        "54e6b1f25ce845b3ae2ef1fb4437effd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "731e8ed3270644878e9b62b65fd5f750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear Canvas",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d39efa2bba6f48efa52a0a47542b30e8",
            "style": "IPY_MODEL_298cd33d2b5c4feeb3546e856853f4db",
            "tooltip": ""
          }
        },
        "d39efa2bba6f48efa52a0a47542b30e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298cd33d2b5c4feeb3546e856853f4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YButf8PRhRuF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "2a7c5781-f493-4e15-bf25-038eb9b8ed01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Please upload your kaggle.json file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-956e243b-cfef-4f44-9e16-51baa6c8fb1b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-956e243b-cfef-4f44-9e16-51baa6c8fb1b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/landlord/handwriting-recognition\n",
            "License(s): CC0-1.0\n",
            "Downloading handwriting-recognition.zip to /content\n",
            " 99% 1.24G/1.26G [00:11<00:00, 218MB/s]\n",
            "100% 1.26G/1.26G [00:11<00:00, 120MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Google Colab and Kaggle Setup\n",
        "# -----------------------------------------\n",
        "# 1. Mount Google Drive: UNCOMMENT the two lines below to save your model to Google Drive.\n",
        "from google.colab import drive output\n",
        "output.enable_custom_widget_manager()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Install Kaggle API\n",
        "!pip install -q kaggle\n",
        "\n",
        "# 3. Upload your kaggle.json file\n",
        "# How to Get Your kaggle.json File\n",
        "# -Log in to your Kaggle account.\n",
        "# -Navigate to your Account settings by clicking on your profile picture in the top-right corner and selecting \"Settings.\"\n",
        "# -Scroll down to the API section.\n",
        "# -Click on the \"Create New API Token\" button. This will immediately trigger the download of the kaggle.json file to your computer.\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Please upload your kaggle.json file\")\n",
        "files.upload()\n",
        "\n",
        "# 4. Configure Kaggle and Download Dataset\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d landlord/handwriting-recognition\n",
        "!unzip -q handwriting-recognition.zip -d handwriting_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up MLFlow and NgGrok.\n",
        "\n",
        "# Setting the authtoken to be able to connect to your NGrok account.\n",
        "# Please replace below AUTH_TOKEN with your own your Ngrok account.\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2zszsS3klrT8kf3LF8OuXC6cY9A_5wYaCnNr9pQnbAG5Re3Gh\"\n",
        "\n",
        "!pip install mlflow pyngrok torchmetrics ipycanvas\n",
        "\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
        "\n",
        "# create remote tunnel using ngrok.com to allow local port access\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if they exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting up auth token\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN) # Removed to avoid potential conflicts with existing sessions\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr = \"5000\", proto = \"http\", bind_tls = True)\n",
        "\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOdnMfKEoVBH",
        "outputId": "efa1c104-8897-4221-9771-398c57c0d5d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting ipycanvas\n",
            "  Downloading ipycanvas-0.13.3-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading databricks_sdk-0.58.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipycanvas) (7.7.1)\n",
            "Requirement already satisfied: pillow>=6.0 in /usr/local/lib/python3.11/dist-packages (from ipycanvas) (11.2.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (3.0.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.47.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (4.9.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.7.14)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (6.5.7)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (5.8.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.2.13)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipycanvas) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (4.24.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.8.0)\n",
            "Downloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipycanvas-0.13.3-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.58.0-py3-none-any.whl (741 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.4/741.4 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, jedi, gunicorn, graphql-core, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, graphql-relay, docker, alembic, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, graphene, databricks-sdk, opentelemetry-sdk, torchmetrics, mlflow-skinny, mlflow, ipycanvas\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed alembic-1.16.4 databricks-sdk-0.58.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 ipycanvas-0.13.3 jedi-0.19.2 lightning-utilities-0.14.3 mlflow-3.1.1 mlflow-skinny-3.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opentelemetry-api-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 pyngrok-7.2.12 torchmetrics-1.7.4\n",
            "MLflow Tracking UI: https://1e6bd45b0536.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "# -----------------------------------------\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchmetrics.functional import accuracy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import mlflow.artifacts\n",
        "from mlflow.tracking import MlflowClient\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "\n",
        "# Imports for Canvas to get the image drawn\n",
        "from ipycanvas import Canvas\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n"
      ],
      "metadata": {
        "id": "rXSOojdPnJWx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration and Hyperparameters\n",
        "# -----------------------------------------\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class Config:\n",
        "\n",
        "    DATA_DIR = './handwriting_data/'\n",
        "    TRAIN_CSV_PATH = os.path.join(DATA_DIR, 'written_name_train_v2.csv')\n",
        "    VALIDATION_CSV_PATH = os.path.join(DATA_DIR, 'written_name_validation_v2.csv')\n",
        "    TEST_CSV_PATH = os.path.join(DATA_DIR, 'written_name_test_v2.csv')\n",
        "\n",
        "    # After mounting your drive, this path will point to a folder where the model is saved.\n",
        "    # For example: '/content/drive/MyDrive/MyModels/handwriting_model.pth'\n",
        "    # If you don't mount Google Drive, it will save to the Colab environment.\n",
        "    MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab/Models/handwriting_crnn_model.pth'\n",
        "\n",
        "    # Experiment name to be used, if this experiment name isn't there in your MLFlow, it will train the model.\n",
        "    # To force a new training, give a new Expeiment name\n",
        "    EXPERIMENT_NAME = 'CRNN_Handwriting_Hyperopt_Full_Experiment'\n",
        "\n",
        "    # Enable training of data on limited data instead of full dataset\n",
        "    ENABLE_TRAINING_ON_LIMITED_DATASET = True\n",
        "\n",
        "    # Image parameters\n",
        "    IMG_HEIGHT = 64\n",
        "    IMG_WIDTH = 256\n",
        "\n",
        "    # Model parameters\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 20\n",
        "    HYPEROPT_EVALS = 15\n",
        "\n",
        "    # Configuration to use for limited data taining\n",
        "    LIMITED_DATA_EPOCHS = 20\n",
        "    LIMITED_DATA_HYPEROPT_EVALS = 3\n",
        "\n",
        "    # Character set\n",
        "    # Dynamically build the character set from the dataset labels\n",
        "    def build_char_set(self):\n",
        "        all_chars = set()\n",
        "        try:\n",
        "            train_df = pd.read_csv(self.TRAIN_CSV_PATH).dropna()\n",
        "            val_df = pd.read_csv(self.VALIDATION_CSV_PATH).dropna()\n",
        "            test_df = pd.read_csv(self.TEST_CSV_PATH).dropna()\n",
        "\n",
        "            for label in train_df['IDENTITY']:\n",
        "                all_chars.update(str(label))\n",
        "            for label in val_df['IDENTITY']:\n",
        "                 all_chars.update(str(label))\n",
        "            for label in test_df['IDENTITY']:\n",
        "                 all_chars.update(str(label))\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: Dataset CSV files not found. Using a default character set.\")\n",
        "            all_chars = set(\" !\\\"#&'()*+,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "\n",
        "        # Sort characters to ensure consistent mapping\n",
        "        sorted_chars = sorted(list(all_chars))\n",
        "        # The character set should include all possible characters in the labels\n",
        "        # plus a blank character for CTC loss, which is usually at index 0\n",
        "        self.CHAR_SET = \"\".join(sorted_chars)\n",
        "        self.CHAR_TO_INT = {char: i + 1 for i, char in enumerate(self.CHAR_SET)}\n",
        "        self.INT_TO_CHAR = {i + 1: char for i, char in enumerate(self.CHAR_SET)}\n",
        "        self.VOCAB_SIZE = len(self.CHAR_SET) + 1 # +1 for the blank token\n",
        "\n",
        "# Instantiate the config and build the character set\n",
        "config = Config()\n",
        "config.build_char_set()\n",
        "\n",
        "if (config.ENABLE_TRAINING_ON_LIMITED_DATASET):\n",
        "    config.EPOCHS = config.LIMITED_DATA_EPOCHS\n",
        "    config.HYPEROPT_EVALS = config.LIMITED_DATA_HYPEROPT_EVALS\n",
        "\n",
        "print(f\"Character set size: {config.VOCAB_SIZE}\")\n",
        "# print(f\"Character set: {config.CHAR_SET}\") # Uncomment to see the full character set"
      ],
      "metadata": {
        "id": "mMnN4lNAnmC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de40abbb-e2ea-4c10-daa5-c530ef0a436e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character set size: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading and Preprocessing\n",
        "# --------------------------------------\n",
        "\n",
        "class HandwritingDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for the handwriting recognition data.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, data_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (pandas.DataFrame): DataFrame with image names and labels.\n",
        "            data_dir (str): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Get image path and label\n",
        "        img_name = self.df.iloc[idx, 0]\n",
        "        label = self.df.iloc[idx, 1]\n",
        "\n",
        "        # Construct full image path\n",
        "        # The CSV contains paths like 'TRAIN_00001.jpg', so we need to find the correct subfolder\n",
        "        # The data is structured in folders like 'train_v2/train/'\n",
        "        # Let's find the correct path\n",
        "\n",
        "        folder_prefix = img_name.split('_')[0].lower() # e.g., 'TRAIN' -> 'train'\n",
        "        sub_folder = f\"{folder_prefix}_v2/{folder_prefix}\"\n",
        "        img_path = os.path.join(self.data_dir, sub_folder, img_name)\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('L') # Convert to grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Encode the label\n",
        "        encoded_label = [config.CHAR_TO_INT[char] for char in str(label)]\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'label': torch.tensor(encoded_label, dtype=torch.long),\n",
        "            'label_length': torch.tensor([len(encoded_label)], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Define transformations\n",
        "# We resize, pad if necessary, and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_HEIGHT, config.IMG_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads and prepares the datasets and dataloaders.\"\"\"\n",
        "    # Read CSVs and drop rows with missing labels\n",
        "    train_df = pd.read_csv(config.TRAIN_CSV_PATH).dropna().reset_index(drop=True)\n",
        "    validation_df = pd.read_csv(config.VALIDATION_CSV_PATH).dropna().reset_index(drop=True)\n",
        "    test_df = pd.read_csv(config.TEST_CSV_PATH).dropna().reset_index(drop=True)\n",
        "\n",
        "    # For demonstration, let's use a smaller subset of the data to speed up training\n",
        "    # You can comment this out to use the full dataset\n",
        "    train_df = train_df.sample(n=20000, random_state=42)\n",
        "    validation_df = validation_df.sample(n=4000, random_state=42)\n",
        "\n",
        "    train_dataset = HandwritingDataset(train_df, config.DATA_DIR, transform=transform)\n",
        "    validation_dataset = HandwritingDataset(validation_df, config.DATA_DIR, transform=transform)\n",
        "    test_dataset = HandwritingDataset(test_df, config.DATA_DIR, transform=transform)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"Custom collate function to handle variable length labels.\"\"\"\n",
        "        images = torch.stack([item['image'] for item in batch])\n",
        "        labels = [item['label'] for item in batch]\n",
        "        label_lengths = torch.stack([item['label_length'] for item in batch]).squeeze()\n",
        "\n",
        "        # Pad labels to the max length in the batch\n",
        "        labels_padded = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
        "\n",
        "        return images, labels_padded, label_lengths\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader"
      ],
      "metadata": {
        "id": "H1sYH8K1oRDk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CRNN Model Architecture\n",
        "# -------------------------------\n",
        "class CRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Recurrent Neural Network (CRNN)\n",
        "    \"\"\"\n",
        "    def __init__(self, img_channels, vocab_size, rnn_hidden_size=256, rnn_layers=2):\n",
        "        super(CRNN, self).__init__()\n",
        "\n",
        "        # --- CNN Feature Extractor ---\n",
        "        # This architecture is designed to take an image of size (C, 64, 256)\n",
        "        # and output a feature map of size (512, 1, 64)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 64 x 32 x 128\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 128 x 16 x 64\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)),  # Output: 256 x 8 x 64\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)),  # Output: 512 x 4 x 64\n",
        "\n",
        "            # This final convolution reduces the height to 1\n",
        "            # H_out = floor((4 + 2*0 - 4)/1 + 1) = 1\n",
        "            nn.Conv2d(512, 512, kernel_size=(4, 1), stride=(1, 1), padding=(0, 0)), # Output: 512 x 1 x 64\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # --- Map-to-Sequence ---\n",
        "        self.map_to_seq = nn.Linear(512, rnn_hidden_size)\n",
        "\n",
        "        # --- RNN Sequence Processor ---\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=rnn_hidden_size,\n",
        "            hidden_size=rnn_hidden_size,\n",
        "            num_layers=rnn_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # --- Fully Connected Layer for Transcription ---\n",
        "        self.fc = nn.Linear(rnn_hidden_size * 2, vocab_size) # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN forward pass\n",
        "        conv_features = self.cnn(x) # (B, C, H, W) -> (B, 512, 1, 64)\n",
        "\n",
        "        # Permute and reshape for RNN\n",
        "        conv_features = conv_features.squeeze(2) # (B, 512, 64)\n",
        "        conv_features = conv_features.permute(0, 2, 1) # (B, 64, 512) -> (Batch, SeqLen, Features)\n",
        "\n",
        "        # Map to sequence\n",
        "        seq_features = self.map_to_seq(conv_features)\n",
        "\n",
        "        # RNN forward pass\n",
        "        rnn_output, _ = self.rnn(seq_features) # (B, SeqLen, HiddenSize*2)\n",
        "\n",
        "        # Transcription layer\n",
        "        output = self.fc(rnn_output) # (B, SeqLen, VocabSize)\n",
        "\n",
        "        # For CTC Loss, the output needs to be (SeqLen, Batch, VocabSize)\n",
        "        output = output.permute(1, 0, 2)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "o5N_J6Er0I_H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation\n",
        "# -------------------------------\n",
        "\n",
        "def ctc_decode(preds, int_to_char_map):\n",
        "    \"\"\"\n",
        "    Decodes the output of the network using a greedy approach (best path).\n",
        "    \"\"\"\n",
        "    preds_idx = torch.argmax(preds, dim=2)\n",
        "    preds_idx = preds_idx.transpose(1, 0) # (Batch, SeqLen)\n",
        "\n",
        "    decoded_texts = []\n",
        "    for i in range(preds_idx.shape[0]):\n",
        "        t = preds_idx[i]\n",
        "        # Remove consecutive duplicates and blank tokens (index 0)\n",
        "        deblanked_t = [p for p in t if p != 0]\n",
        "        unique_t = [deblanked_t[j] for j in range(len(deblanked_t)) if j == 0 or deblanked_t[j] != deblanked_t[j-1]]\n",
        "\n",
        "        text = ''.join([int_to_char_map.get(c.item(), '') for c in unique_t])\n",
        "        decoded_texts.append(text)\n",
        "\n",
        "    return decoded_texts\n",
        "\n",
        "def train_one_epoch(model, optimizer, criterion, train_loader, device):\n",
        "    \"\"\"Trains the model for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "        images, labels, label_lengths = batch\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        label_lengths = label_lengths.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        preds = model(images)\n",
        "        log_probs = F.log_softmax(preds, dim=2)\n",
        "\n",
        "        # Calculate input lengths for CTC loss\n",
        "        # The sequence length from the model is preds.size(0)\n",
        "        input_lengths = torch.full(size=(images.size(0),), fill_value=preds.size(0), dtype=torch.long)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(log_probs, labels, input_lengths, label_lengths)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # Clip gradients to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate(model, criterion, val_loader, device):\n",
        "    \"\"\"Validates the model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            images, labels, label_lengths = batch\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            label_lengths = label_lengths.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            preds = model(images)\n",
        "            log_probs = F.log_softmax(preds, dim=2)\n",
        "            input_lengths = torch.full(size=(images.size(0),), fill_value=preds.size(0), dtype=torch.long)\n",
        "\n",
        "            # Loss\n",
        "            loss = criterion(log_probs, labels, input_lengths, label_lengths)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Decode predictions for evaluation\n",
        "            decoded_preds = ctc_decode(preds.cpu(), config.INT_TO_CHAR)\n",
        "            all_preds.extend(decoded_preds)\n",
        "\n",
        "            # Decode ground truth labels\n",
        "            for l in labels:\n",
        "                text = ''.join([config.INT_TO_CHAR.get(c.item(), '') for c in l if c != 0])\n",
        "                all_labels.append(text)\n",
        "\n",
        "    # Calculate Character Error Rate (CER) and Word Error Rate (WER) - simplified\n",
        "    # Note: A proper CER/WER calculation uses edit distance. This is a simple accuracy check.\n",
        "    correct_predictions = sum(1 for p, l in zip(all_preds, all_labels) if p == l)\n",
        "    accuracy = correct_predictions / len(all_labels)\n",
        "\n",
        "    return total_loss / len(val_loader), accuracy\n"
      ],
      "metadata": {
        "id": "OjRXby9K2Dgd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing model to the Google Drive at config.MODEL_SAVE_PATH\n",
        "# Download model to store for future usage of prediction without training without MLFlow\n",
        "# Params: pass the run id to download the model from\n",
        "def storingModel(run_id):\n",
        "    print(f\"\\n--- Downloading Model to local file ---\")\n",
        "    model_uri = f\"runs:/{run_id}/model\"\n",
        "\n",
        "    # This will download the model files (MLmodel, conda.yaml, etc.) into the specified directory\n",
        "    local_path = mlflow.artifacts.download_artifacts(artifact_uri=model_uri)\n",
        "    shutil.copytree(local_path, config.MODEL_SAVE_PATH, dirs_exist_ok=True)\n",
        "    print(f\"Model downloaded to: {config.MODEL_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "4kLjiHL2Nlb-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up objective funtion whose role is to minimize the loss\n",
        "def objective(params):\n",
        "    with mlflow.start_run(nested=True) as run:\n",
        "        # Hyperparameters from Hyperopt\n",
        "        rnn_hidden_size = int(params['rnn_hidden_size'])\n",
        "        rnn_layers = int(params['rnn_layers'])\n",
        "        learning_rate = params['lr']\n",
        "        epochs = config.EPOCHS\n",
        "\n",
        "        # Log params to MLflow\n",
        "        mlflow.log_params({\n",
        "            \"rnn_hidden_size\": rnn_hidden_size,\n",
        "            \"rnn_layers\": rnn_layers,\n",
        "            \"learning_rate\": learning_rate\n",
        "        })\n",
        "\n",
        "        train_loader, val_loader, _ = load_data()\n",
        "\n",
        "        model = CRNN(img_channels=1, vocab_size=config.VOCAB_SIZE, rnn_hidden_size=rnn_hidden_size, rnn_layers=rnn_layers).to(device)\n",
        "        criterion = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=False)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\n--- Epoch {epoch+1}/{config.EPOCHS} ---\")\n",
        "\n",
        "            train_loss = train_one_epoch(model, optimizer, criterion, train_loader, device)\n",
        "            val_loss, val_accuracy = validate(model, criterion, val_loader, device)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\")\n",
        "\n",
        "            mlflow.log_metrics({\n",
        "                \"train_loss\": train_loss,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy\n",
        "            }, step=epoch)\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "\n",
        "\n",
        "        mlflow.log_metric(\"best_val_loss\", best_val_loss)\n",
        "\n",
        "        # Change the model logging to also log the signature\n",
        "        mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
        "\n",
        "        # Download model to store for future usage\n",
        "        storingModel(run.info.run_id)\n",
        "\n",
        "        return {'loss': best_val_loss, 'status': STATUS_OK}\n",
        "\n",
        "# --- Define hyperparameter space, choices of hyperparameter values which will be tried to find the best combination ---\n",
        "search_space = {\n",
        "    'rnn_hidden_size': hp.choice('rnn_hidden_size', [256, 512]),\n",
        "    'rnn_layers': hp.choice('rnn_layers', [2]),\n",
        "    'lr': hp.loguniform('lr', np.log(2e-4), np.log(1e-3)),   # 0.0002 to 0.001\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "jlww42D93YA6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperopt\n",
        "# --- Train model and perform Hyperparameter optimization with fmin ---\n",
        "def train_model_with_hyperopt():\n",
        "    mlflow.pytorch.autolog(log_models = False)\n",
        "\n",
        "    best_hyperparameters = fmin(\n",
        "        fn = objective,\n",
        "        space = search_space,\n",
        "        algo = tpe.suggest,\n",
        "        max_evals = config.HYPEROPT_EVALS\n",
        "    )\n",
        "\n",
        "    print(\"\\nTraining finished!\")\n",
        "    print(\"\\nBest hyperparameters found for the model:\")\n",
        "    print(best_hyperparameters)\n",
        "    print(hyperopt.space_eval(search_space, best_hyperparameters))\n",
        "    return best_hyperparameters\n"
      ],
      "metadata": {
        "id": "wExt5SbI8YrV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on a Single Image\n",
        "# ------------------------------------\n",
        "def predict_word(model, image_path, device):\n",
        "    \"\"\"\n",
        "    Takes an image path and predicts the handwritten word.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess the image\n",
        "    image = Image.open(image_path).convert('L')\n",
        "\n",
        "    # Resize to match model's expected size\n",
        "    # img = image.resize((256, 64), Image.BILINEAR)\n",
        "\n",
        "    print(\"Batch shape before unsqueeze:\", image.height, image.width)\n",
        "    image = transform(image).unsqueeze(0) # Add batch dimension\n",
        "    image = image.to(device)\n",
        "\n",
        "    print(\"Batch shape at the end:\", image.shape)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(image)\n",
        "\n",
        "    # Decode the prediction\n",
        "    decoded_text = ctc_decode(preds.cpu(), config.INT_TO_CHAR)\n",
        "\n",
        "    # Display the image and prediction\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    plt.imshow(Image.open(image_path), cmap='gray')\n",
        "    plt.title(f\"Predicted Word: {decoded_text[0]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return decoded_text[0]"
      ],
      "metadata": {
        "id": "LDM5uQkA2TXB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding best model from the runs in the experiment\n",
        "# If Experiment itself is not there, it creates the experiment as well.\n",
        "# Returns the Best run id from the experiment, or None if there is no run in the experiment\n",
        "# ------------------------------------\n",
        "def finding_best_model():\n",
        "    # Load best model from MLflow's model registry\n",
        "    # Getting instance of the experiment\n",
        "    experiment_name = config.EXPERIMENT_NAME\n",
        "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
        "\n",
        "    # Setting up MLFlow client\n",
        "    client = MlflowClient()\n",
        "\n",
        "    # Best MLFlow run id\n",
        "    best_run_id = None\n",
        "\n",
        "    if experiment is not None:\n",
        "        experiment_id = experiment.experiment_id\n",
        "        # TO DO: confirm which metrics to use metrics.val_loss or best_val_loss\n",
        "        best_runs = client.search_runs(\n",
        "            experiment_id,\n",
        "            order_by=[\"metrics.best_val_loss ASC\"],\n",
        "            max_results=1\n",
        "        )\n",
        "\n",
        "        if best_runs: # Check if the list is not empty\n",
        "            best_run_id = best_runs[0].info.run_id # Access the first element\n",
        "            print(f\"Experiment '{experiment_name}' has best run with id {best_run_id}.\")\n",
        "        else:\n",
        "            print(f\"Experiment '{experiment_name}' exists but has no runs.\")\n",
        "            best_run_id = None\n",
        "\n",
        "    else:\n",
        "        experiment_id = client.create_experiment(name=experiment_name)\n",
        "        print(f\"Experiment '{experiment_name}' does not exist. Created new experiment with ID: {experiment_id}\")\n",
        "        best_run_id = None\n",
        "\n",
        "    return best_run_id"
      ],
      "metadata": {
        "id": "GOkC1thERbw_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the canvas\n",
        "canvas = Canvas(width=256, height=64,sync_image_data=True)\n",
        "\n",
        "# Track mouse state\n",
        "is_drawing = {'active': False}\n",
        "\n",
        "# Drawing function\n",
        "def handle_mouse_down(x, y):\n",
        "    is_drawing['active'] = True\n",
        "    canvas.begin_path()\n",
        "    canvas.move_to(x, y)\n",
        "\n",
        "def handle_mouse_up(x, y):\n",
        "    is_drawing['active'] = False\n",
        "\n",
        "def handle_mouse_move(x, y):\n",
        "    if is_drawing['active']:\n",
        "        canvas.line_to(x, y)\n",
        "        canvas.stroke()\n",
        "\n",
        "# Bind mouse events\n",
        "canvas.on_mouse_down(handle_mouse_down)\n",
        "canvas.on_mouse_up(handle_mouse_up)\n",
        "canvas.on_mouse_move(handle_mouse_move)\n",
        "\n",
        "# Create a Clear button\n",
        "clear_button = widgets.Button(description=\"Clear Canvas\")\n",
        "\n",
        "def clear_canvas(b):\n",
        "    canvas.clear()\n",
        "\n",
        "clear_button.on_click(clear_canvas)\n",
        "\n",
        "# Display canvas and button\n",
        "display(canvas, clear_button)\n",
        "\n",
        "print(\"Draw on the canvas above. When done, run the next cell to capture and process the image.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "f128981227384236b16635267255335b",
            "1bec5f64caf34a93bebdbf9c5f4f341c",
            "54e6b1f25ce845b3ae2ef1fb4437effd",
            "731e8ed3270644878e9b62b65fd5f750",
            "d39efa2bba6f48efa52a0a47542b30e8",
            "298cd33d2b5c4feeb3546e856853f4db"
          ]
        },
        "id": "5cBRyHqJFKkj",
        "outputId": "2100ecea-d5ba-4e06-b67c-94c39bb1d06a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Canvas(height=64, sync_image_data=True, width=256)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f128981227384236b16635267255335b"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Clear Canvas', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "731e8ed3270644878e9b62b65fd5f750"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw on the canvas above. When done, run the next cell to capture and process the image.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "4ke0wwQBdyXp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_center_canvas_image_clean(path=\"centered_drawn_image.jpg\", target_size=(256, 64), threshold=200, binarize=True):\n",
        "    # Get canvas image data\n",
        "    img_data = canvas.get_image_data()\n",
        "    rgba = np.array(img_data)\n",
        "\n",
        "    # Blend alpha over white background\n",
        "    white_bg = np.ones_like(rgba[..., :3]) * 255\n",
        "    alpha = rgba[..., 3:4] / 255.0\n",
        "    rgb = rgba[..., :3] * alpha + white_bg * (1 - alpha)\n",
        "    rgb = rgb.astype(np.uint8)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    img = Image.fromarray(rgb).convert('L')\n",
        "\n",
        "    # Optionally enhance contrast\n",
        "    img = ImageEnhance.Contrast(img).enhance(2.0)\n",
        "\n",
        "    # Optionally binarize (remove background noise)\n",
        "    if binarize:\n",
        "        img_np = np.array(img)\n",
        "        img_np = np.where(img_np < threshold, 0, 255).astype(np.uint8)  # Hard threshold\n",
        "        img = Image.fromarray(img_np)\n",
        "\n",
        "    # Resize height only\n",
        "    img = img.resize((img.width, target_size[1]), Image.BILINEAR)\n",
        "\n",
        "    # Center horizontally\n",
        "    img_np = np.array(img)\n",
        "    col_sum = np.sum(img_np < 255, axis=0)  # Now binary, so <255 means ink\n",
        "    non_empty_cols = np.where(col_sum > 0)[0]\n",
        "\n",
        "    if len(non_empty_cols) > 0:\n",
        "        left = non_empty_cols[0]\n",
        "        right = non_empty_cols[-1]\n",
        "        cropped = img.crop((left, 0, right + 1, img.height))\n",
        "        cropped = cropped.resize((cropped.width, target_size[1]), Image.BILINEAR)\n",
        "\n",
        "        pad_total = target_size[0] - cropped.width\n",
        "        pad_left = pad_total // 2\n",
        "        pad_right = pad_total - pad_left\n",
        "        centered = ImageOps.expand(cropped, border=(pad_left, 0, pad_right, 0), fill=255)\n",
        "    else:\n",
        "        print(\"Warning: image is blank.\")\n",
        "        centered = img.resize(target_size)\n",
        "\n",
        "    centered.save(path)\n",
        "    return centered\n",
        "\n",
        "filepath_to_predict2 = \"centered_drawn_image.jpg\"\n",
        "image_to_predict2 = save_and_center_canvas_image_clean(path=filepath_to_predict2)\n",
        "plt.imshow(image_to_predict2, cmap=\"gray\")\n",
        "image_to_predict2.width, image_to_predict2.height"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jvzw2eZzj_lH",
        "outputId": "1e895458-1880-459c-e96e-d55b1fd3907f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == '__main__':\n",
        "    # This check prevents running the training automatically when the script is imported.\n",
        "    # To train the model, uncomment the following line in your Colab notebook.\n",
        "\n",
        "    # Define the device to be used for training and prediction\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # To store prediction_model\n",
        "    prediction_model = None\n",
        "\n",
        "    # Load model from file if exists\n",
        "    if os.path.exists(config.MODEL_SAVE_PATH):\n",
        "        print(f\"\\n--- Model loaded from the file ---\")\n",
        "        # Specify map_location to load the model onto the CPU if CUDA is not available\n",
        "        prediction_model = mlflow.pytorch.load_model(config.MODEL_SAVE_PATH, map_location=device)\n",
        "    else:\n",
        "        best_run_id = finding_best_model()\n",
        "        if best_run_id is None:\n",
        "            print(\"There is no registered run for the model in MLflow's model registry under the Experiment. Starting to train the model.\")\n",
        "\n",
        "            # Setting up the Experiment before starting the training\n",
        "            mlflow.set_experiment(config.EXPERIMENT_NAME)\n",
        "\n",
        "            # Run hyperparameter optimization and training\n",
        "            best_hyperparameters = train_model_with_hyperopt()\n",
        "\n",
        "            # Finding best model from the runs to use for predictions below\n",
        "            best_run_id = finding_best_model()\n",
        "\n",
        "        print(f\"Best run ID which is used to get the model for predictions: {best_run_id}\")\n",
        "\n",
        "\n",
        "    # --- Example of how to use the prediction function ---\n",
        "    # You would need a trained model file ('best_crnn_model.pth') and an image.\n",
        "\n",
        "    print(\"\\nTo run prediction, you need a trained model.\")\n",
        "    print(\"First, run the main() function to train and save a model.\")\n",
        "    print(\"Then, you can use the predict_word() function like this:\")\n",
        "    print(\"`predict_word(trained_model, 'path/to/your/image.png', device)`\")\n",
        "\n",
        "    # Example usage with a sample image from the validation set\n",
        "    # Let's find a sample image to test with\n",
        "    try:\n",
        "        validation_df_for_pred = pd.read_csv(config.TEST_CSV_PATH).dropna().reset_index(drop=True)\n",
        "        sample_row = validation_df_for_pred.sample(1).iloc[0]\n",
        "        sample_img_name = sample_row['FILENAME']\n",
        "        sample_label = sample_row['IDENTITY']\n",
        "\n",
        "\n",
        "        if os.path.exists(filepath_to_predict2):\n",
        "            print(f\"Using the provided image at path: {filepath_to_predict2}\")\n",
        "            sample_img_path = filepath_to_predict2\n",
        "        else:\n",
        "            sample_img_path = os.path.join(config.DATA_DIR, 'test_v2/test', sample_img_name)\n",
        "            print(f\"\\n--- Running Prediction on a Sample Image ---\")\n",
        "            print(f\"Image: {sample_img_name}, True Label: {sample_label}\")\n",
        "\n",
        "\n",
        "        if os.path.exists(sample_img_path):\n",
        "\n",
        "            # Load a pre-trained model if it exists, otherwise you need to train first\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            if prediction_model is None and best_run_id is not None:\n",
        "                model_uri = f\"runs:/{best_run_id}/model\"\n",
        "\n",
        "                print(f\"\\n--- Downloading Model from best run id ---\")\n",
        "                # This will download the model files (MLmodel, conda.yaml, etc.) into the specified directory\n",
        "                local_path = mlflow.artifacts.download_artifacts(artifact_uri=model_uri)\n",
        "                shutil.copytree(local_path, config.MODEL_SAVE_PATH, dirs_exist_ok=True)\n",
        "                print(f\"Model downloaded to: {config.MODEL_SAVE_PATH}\")\n",
        "\n",
        "                # Load model from the best run in the experiment\n",
        "                # Specify map_location to load the model onto the CPU if CUDA is not available\n",
        "                prediction_model = mlflow.pytorch.load_model(model_uri, map_location=device)\n",
        "\n",
        "\n",
        "            if (prediction_model):\n",
        "                  # Now best_prediction_model is a PyTorch model, ready for inference\n",
        "                  prediction_model.eval()\n",
        "                  print(f\"\\n--- Predicting from MLFlow version of the model ---\")\n",
        "                  predict_word(prediction_model, sample_img_path, device)\n",
        "\n",
        "            else:\n",
        "                print(\"No model found in MLflow's model registry.\")\n",
        "                # Get the best rnn_layers from the hyperparameter search results\n",
        "                best_rnn_layers = hyperopt.space_eval(search_space, best_hyperparameters)['rnn_layers']\n",
        "                best_rnn_hidden_size = hyperopt.space_eval(search_space, best_hyperparameters)['rnn_hidden_size']\n",
        "\n",
        "                # Instantiate the model with the best hyperparameters\n",
        "                prediction_model = CRNN(img_channels=1, vocab_size=config.VOCAB_SIZE,\n",
        "                                        rnn_hidden_size=best_rnn_hidden_size,\n",
        "                                        rnn_layers=best_rnn_layers).to(device)\n",
        "                if os.path.exists(config.MODEL_SAVE_PATH):\n",
        "                    # Specify map_location to load the model onto the CPU if CUDA is not available\n",
        "                    prediction_model.load_state_dict(torch.load(config.MODEL_SAVE_PATH, map_location=device))\n",
        "                    predict_word(prediction_model, sample_img_path, device)\n",
        "                else:\n",
        "                    print(f\"\\nCould not find {config.MODEL_SAVE_PATH}.\")\n",
        "                    print(\"Please train the model first\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"Could not find sample image at: {sample_img_path}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nCould not find validation CSV. Please ensure the dataset is downloaded and extracted correctly.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"An error occurred during model loading or prediction: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "HDgHXE6ZUcWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "38179441-41a4-4350-bb1e-d9e3d899818b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Model loaded from the file ---\n",
            "\n",
            "To run prediction, you need a trained model.\n",
            "First, run the main() function to train and save a model.\n",
            "Then, you can use the predict_word() function like this:\n",
            "`predict_word(trained_model, 'path/to/your/image.png', device)`\n",
            "Using the provided image at path: centered_drawn_image.jpg\n",
            "\n",
            "--- Running Prediction on a Sample Image ---\n",
            "Image: TEST_4758.jpg, True Label: ELSA\n",
            "\n",
            "--- Predicting from MLFlow version of the model ---\n",
            "Batch shape before unsqueeze: 64 256\n",
            "Batch shape at the end: torch.Size([1, 1, 64, 256])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}